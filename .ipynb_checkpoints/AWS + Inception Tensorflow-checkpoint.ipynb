{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Distributed Tensorflow on Ec2\n",
    "\n",
    "## AWS Setup \n",
    "### Navigating to the Console\n",
    "- Go to the ec2 console page by clicking on \"Services\" (Top left), then EC2 in the dropdown.\n",
    "    - On this page you'll see statistics about how many \"instances\" are running, etc.\n",
    "- Click the instances tab in the left\n",
    "    - This page shows you all the instances that are running / terminated / stopped\n",
    "        - Stopping an instance saves the state of the machine (files, etc from previous runs are left unchanged). But the machine is not alive. \n",
    "        - Terminating an instance shuts it down, and the machine is basically gone forever.\n",
    "        - A running instance is currently alive.\n",
    "               \n",
    "### Launching your first EC2\n",
    "- Click the blue \"launch instance\" button in the top\n",
    "- Make sure you are in the (\"US-WEST oregon\") region, in the top left corner\n",
    "- Select the \"Ubuntu\" AMI \n",
    "    - Note: AMI = Amazon machine instance = a saved machine state (containing installed software, etc)\n",
    "        - Amazon has a \"marketplace\" of AMIs which allow launching instances pre-installed with specific software packages. Additionally you can create your own AMI after configuring a machine with installed software and share it.\n",
    "- Select t2.micro (free tier) and click \"Next:Configure...\"\n",
    "- Leave this page unchanged (skip the \"Configure Instance Details\" page). Click next.\n",
    "- Leave this page unchanged (skip the \"Add Storage\" page). Click next.\n",
    "- Leave this page unchanged (skip the \"Tag Instance\" page). Click next.\n",
    "- On \"Step 6: Configure Security Group\", make sure SSH can be accessed from a source of \"Anywhere\". Click Review and Launch.\n",
    "- Click Launch\n",
    "    - A popup will appear telling you to select a key pair. Since this is our first time launching an instance, select create a new key pair, name it, and download it to a safe location on your machine. On later launches, you should use pre-existing key pairs.\n",
    "    - Select Launch Instance\n",
    "    \n",
    "### SSH'ing into your EC2 machine\n",
    "- Navigate to the instances tab of the EC2 console.\n",
    "- After following the steps for launching the EC2 machine, you should see a new entry in the instance page.\n",
    "- Selecting the checkbox next to it will show details regarding the machine\n",
    "    - Click the Connect button at the top. It will tell you how to ssh into that instance.\n",
    "    - Note: the .pem they refer to is the key file you downloaded when launching the EC2.\n",
    "   \n",
    "### Distributed Tensorflow \n",
    "#### Basic Info\n",
    "- In distributed tensorflow there are 2 types of machines \n",
    "    - Worker machines, which do gradient computation\n",
    "    - Parameter servers, which hold the model\n",
    "    - See https://www.tensorflow.org/versions/r0.11/how_tos/distributed/index.html for more info\n",
    "- Running distributed tensorflow means\n",
    "    - Running tensorflow individually across multiple machines (E.G: with 10 machines, tensorflow will be running on each and every one of them)\n",
    "    - How tensorflow knows which machines are workers, and which are parameter servers\n",
    "        - Providing the private ips of the machines that create the cluster (this is done through command line args)\n",
    "        - Providing the type of worker that the machine is via an index (this is done through command line args)\n",
    "        - Example: \n",
    "            - ./bazel-bin/inception/imagenet_distributed_train [... other_args here ...] --worker_hosts='172.31.7.97:1234,172.31.14.51:1234,172.31.9.233:1234,172.31.8.86:1234,172.31.7.247:1234' --ps_hosts='172.31.13.165:1234' --task_id=0 --job_name='worker'\n",
    "            - worker_hosts is a string containing a comma separated list of private ips in the cluster\n",
    "            - ps_hosts is a string containing a comma separated list of private ips in the cluster\n",
    "            - job_name is a string either \"worker\" or \"ps\" specifying the type of machine\n",
    "            - task_id is an integer (0 indexed) specifying the index of the machine in either worker_hosts if the machine is a worker, or ps_hosts if the machin is a ps\n",
    "    - So if you want a cluster of 10 machines to run the inception model, you need to launch 10 instances on EC2, ssh into each one, and run the appropriate command. I have written some scripts (though they are quite ugly) to make this easier. There are probably better solutions to managing this, but I did not seem to find many that were simple and widely used. Definitely let me know if you find any better ways to manage these jobs!\n",
    "    \n",
    "### Launching Via Python Script (MNIST ConvNN)\n",
    "#### Github\n",
    "\n",
    "Github: https://github.com/agnusmaximus/DistributedMNIST/tree/clean_mnist\n",
    "\n",
    "Path to script: https://github.com/agnusmaximus/DistributedMNIST/blob/clean_mnist/tools/tf_ec2.py\n",
    "\n",
    "#### Overview\n",
    "The posted python script allows users to manage and configure aws ec2 clusters and run distributed Tensorflow on them (it currently works on MNIST convolutional neural network). It works by having a configuration of the settings of the cluster in a python dictionary, and then using that information to launch / manage clusters. \n",
    "\n",
    "As described in the Distributed Tensorflow section, there are two different types of machines -- workers (the master is a type of worker) and parameter servers (ps for short). The script allows you to configure the number of EC2 machines assigned to each, as well as what type of machine is assigned to them, as well as AMI.\n",
    "\n",
    "Additionally, since training a distributed model oftentimes requires evaluating the model on the dataset to gather loss / accuracy data, the script also launches a separate \"evaluator\" machine whose sole purpose is to evaluate the trained model (loaded through tensorflow checkpoint files) on the data. The evaluator machine constantly checks to see if a new checkpoint file has been generated -- if so, it loads the new model, and evaluates on the data immediately. Output is written to the same shared directory as the checkpoint. \n",
    "\n",
    "These checkpoint files are written to a shared file system (through NFS). Worker / PS output logs are also written to this shared file system to allow easy centralized debugging. This means you can \"cd\" into the shared filesystem from one of the workers and look at all the logs generated by each machine in the cluster. However this also means that AWS needs to be set up to use NFS. \n",
    "\n",
    "#### Getting Set Up\n",
    "- Do the basic AWS setup (like creating key-pair, etc)\n",
    "- Install the cli to AWS\n",
    "    - https://aws.amazon.com/cli/\n",
    "    - http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-set-up.html\n",
    "- Set up an EFS (elastic file system) for the NFS shared directory\n",
    "    - Navigate to the EFS page (you can click \"services\" and search for \"efs\")\n",
    "    - Click \"Create File System\"\n",
    "    - Select all us-west availability zones and click next\n",
    "    - Add an appropriate name for the file system (your name would be good, as it would avoid confusion. I didn't do this, but I should have...)\n",
    "    - Finish by clicking \"Create Filesystem\"\n",
    "    \n",
    "#### Configuration Description\n",
    "The configuration file is how you describe cluster properties (number of workers, ps's, AMI, etc). Here I  list several of the more used parameters and describe what they are.\n",
    "- name - Should be a name for the cluster configuration. It will be used to name the NFS shared directory where all the logs for all the workers are stored.\n",
    "- key_name - Name of the key pair used to interface with AWS. This is required to distinguish machines of one user from another. That way the shutdown command doesn't shut someone else's machines. \n",
    "- n_masters - Number of master workers. This should always be 1.\n",
    "- n_workers - Number of workers (not including master). This should be set to however many workers you want in the cluster.\n",
    "- n_ps - Number of parameter servers. This should be set to however many parameter servers you want in the cluster.\n",
    "- n_evaluators - Number of evaluators. Probably should be 1, since only a single evaluator is required to evaluate a newly written model against data.\n",
    "- method - \"reserved\" or \"spot\". Reserved is required for t2 machines (since they don't support spot instances). Spot instances require you to bid on the price of the machines you're after. Use spot to save money.\n",
    "- region - Should be \"us-west-2\"\n",
    "- availability_zone - Depends on region, but for region=\"us-west-2\" should be one of \"us-west-2a\",\"us-west-2b\",\"us-west-2c\". Sometimes spot instances are much cheaper in different availability zones. It's useful to check the pricing history on the EC2 console for this data.\n",
    "- master_type,worker_type,ps_type,evaluator_type - machine tier specification (e.g m4.2xlarge).\n",
    "- image_id - AMI id which specifies the software that is to be pre-installed on the launched machines. This is important because you should choose an AMI with tensorflow (or additionally your data and extra software) installed. ami-2306ba43 is the TensorflowMnistBase AMI, which has the DistributedMNIST repository downloaded, and tensorflow version 0.12.1 installed. (It also has some basic python packages installed like numpy etc). This is a good starting point for creating new AMI's that rely on tensorflow. \n",
    "- spot_price - Price limit for each machine for spot requests. Only matters if method=\"spot\"\n",
    "- path_to_keyfile - Path to your key pair file. Better to use absolute paths...\n",
    "- nfs_ip_address - Set this to the ip address of the EFS for the particular availability zone that was set up in the \"Set Up\" section. To access this info, navigate to the EFS page, click your EFS, and it should tell you the specific ip addressesof the EFS for each availability zone. The availability zone of the nfs ip address should match the availability_zone configuration previously specified.\n",
    "- nfs_mount_point - Path to the shared filesystem. Something like /home/ubuntu/my_nfs_mount_point. In it will contain all the logs for all clusters (distinguished by the cluster name specified earlier).\n",
    "\n",
    "#### Basic Usage / Commands\n",
    "- python tf_ec2.py ...\n",
    "- python tf_ec2.py launch - Launch instances according to configuration.\n",
    "- python tf_ec2.py shutdown - Shut down EVERYTHING down. All machines, all spot requests, etc.\n",
    "- python tf_ec2.py run_tf - Assumes the cluster has been launched. Runs tensorflow on the instances. Then prints commands to ssh into the workers. \n",
    "- python tf_ec2.py kill_all_python - runs \"pkill -9 python\" on all machines. Useful for stopping tensorflow.\n",
    "- python tf_ec2.py clean_launch_and_run - shutdown, then launch, then run_tf\n",
    "\n",
    "#### Potential Issues\n",
    "- IMPORTANT: All of the above so far runs the MNIST distributed training code. Tweaking may be required to run on inception, etc.\n",
    "    - There may be a problem with the evaluation script (which is currently for MNIST), since I set batch size equivalent to the number of data points (yeah that's bad...). This works on MNIST since it's tiny, but won't work with larger data.\n",
    "    - The current code (specifically for MNIST) automatically downloads data before each run (this is specific to MNIST). If data is large, it may be helpful to download the data beforehand, create a snapshot of the machine, then use the AMI for machines.\n",
    "    - The current training code does not set up a pipeline to process (e.g: distort) inputs like the inception code. It just uses feed dictionaries.\n",
    "    - Since the current code is designed for MNIST, it may be necessary to make changes to accomodate your requirements. (Sorry about this, I was not thinking generality / reusability when I wrote this.)\n",
    "- If you change the cluster configuration (like the number of overall machines in your cluster), you need to relaunch.\n",
    "- I have not tested managing multiple clusters (the code is designed so that you can do this, but I have never tried it)... So it may not work (Again, sorry!).\n",
    "\n",
    "#### Help\n",
    "If any unexpected error happens or if there are any questions, definitely send me an email at agnusmaximus@gmail.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
